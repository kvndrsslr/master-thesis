\section{Learning Approach}
\label{sec:gpapproach}
We have seen that even the most simplistic standard enrichment operators already require a fair amount of configuration.
Moreover, one has to be very well versed with the set of available enrichment operators in order to specify how they should be combined to an adequate enrichment graph for the specific use case at hand.

Together with the additional complexity induced by the modular design of \ac{DEER2}, we can assert that it requires expert knowledge to operate it.\\

This however goes against our initial motivation of presenting an approach accessible also to novice users.

In this section, we will therefore develop a \ac{GP}-based approach for the automatic learning of enrichment graphs.
To that end, we will first define our learning problem in \autoref{ssec:learningproblem}.
After that, we will introduce our baseline algorithm in \autoref{ssec:baseline} which is subject
to subsequent tweaks and extensions described in \autoref{ssec:compaction} through~\ref{ssec:sgoapproach}.

\subsection{The Learning Problem}
\label{ssec:learningproblem}

The problem under study is that of finding an adequate enrichment graph for a given training example.

Since for this work we do not wish to consider multi-objective learning, we restrict ourselves to learning the subclass of inherently confluent enrichment graphs.
We will furthermore restrict our study to enrichment graphs where the maximum in-degree of the involved enrichment operators and the number of involved dataset emitters are at most two. \\

Therefore, a training example will consist of a list of source training datasets $\left(D_{s_1}, \dots, D_{s_n}\right)\in\mathcal{D}^n$ with $n\in\{1,2\}$ as well as a single target training dataset $D_t \in \mathcal{D}$.\\

The output of \ac{RDF} enrichment is commonly expected to have a regular structure, which more formally means that the output dataset will consist of a number of approximately isomorphic \ac{RDF} subgraphs.

Therefore, we will regard the source and target datasets as \acfp{SCBD} of sufficient depth to representatively capture the desired enrichment on just one of these approximately isomorphic subgraphs.
This is in accordance with the observation that a single \ac{SCBD} is sufficient for the training of enrichment pipelines in~\cite{sherif:2015a}.\\

\subsection{Baseline Algorithm}
\label{ssec:baseline}

In order to solve the learning problem defined above, we will use a population-based \acf{GP} algorithm and additionally employ techniques from \acf{MEP}.

We choose enrichment tables as the encoding of the programs (\ie enrichment graphs) that are to be learned by our approach.
In order to tailor our encoding fit for use with \ac{MEP} we will first define the notion of a \emph{multi-expressive enrichment table}.

\subsubsection{Multi-Expressive Enrichment Table}
\label{sssec:meet}
We call a row within an enrichment table an \emph{output row}, if it is not used as input to a subsequent row.

Please verify that output rows by definition always correspond to dataset acceptors and that our previous definition of enrichment tables allows for only a single output row, as they must be isomorphic to inherently confluent enrichment graphs.\\

We now define a multi-expressive enrichment table as an enrichment table which has more than one \emph{output row}.

A normal enrichment table $\mathbb{T}^{(\text{norm})}$ can be obtained from a multi-expressive enrichment table in a recursive fashion $\mathbb{T}$ as follows:

\begin{itemize}
  \item Let $\mathbb{T}^{(\text{norm})}$ be an empty enrichment table.
  \item Let $\mathcal{T}$ be an empty set.
  \item Let $\zeta \colon \mathbb{N} \to \mathbb{N}$ denote a bijective mapping of index numbers, which initially only contains the mapping $0 \mapsto 0$.
  \item We select one of the output rows with index $r$ as reference. This row is added together with its index to the list $\mathcal{T}$ as $\mathcal{T} \coloneq \mathcal{T}\circ (\mathbb{T}_r, r)$.
  \item When adding a row $\mathbb{T}_i$ to $\mathcal{T}$, we also add all the row-index pairs $\left(\left(\mathbb{T}_{\mathbb{T}_{i,4}}, \mathbb{T}_{i,4} \right), \dots, \left( \mathbb{T}_{\mathbb{T}_{i,\mathbb{T}_{i,3}}}, \mathbb{T}_{i,\mathbb{T}_{i,3}} \right) \right)$ to $\mathcal{T}$.
  \item We then sort the entries $\left(\mathbb{T}_k, i_k\right)\in \mathcal{T}$ according to the index $i_k$ in ascending order.
  \item For each entry $\left(\mathbb{T}_k, i_k\right)\in \mathcal{T}$, $k\in \left(1, \dots, |\mathcal{T}|\right)$, we add $\mathbb{T}_k$ to $\mathbb{T}^{(\text{norm})}$ and keep track of the mapping from the old row number to the new row number by adding the mapping $i_k \mapsto k$ to $\zeta$.
  \item We then replace the input definition column entries \\$\mathbb{T}^{(\text{norm})}_{k, 4}, \dots, \mathbb{T}^{(\text{norm})}_{k, \mathbb{T}^{(\text{norm})}_{k, 3}}$ with $\zeta\left(\mathbb{T}^{(\text{norm})}_{k, 4}\right), \dots, \zeta\left(\mathbb{T}^{(\text{norm})}_{k, \mathbb{T}^{(\text{norm})}_{k, 3}}\right)$.
\end{itemize}


\begin{table}[tb]
\caption[Example of a multi-expressive enrichment table]{Example of a multi-expressive enrichment table. Output rows are marked in red color. When selecting the 8th output row as reference we can recursively reconstruct the normal enrichment table given in  \autoref{tab:exampleenrichmentgraph}. For better readability we prepended the row number followed by a colon in each row.}
\centering
\begin{tabular}{lc|c|c|c|c|c}
  1: & $\mathbb{o}_1$ & $P_1$ & 0 & 0 & 0 & 0\\ \hline
  2: & $\mathbb{o}_2$ & $P_2$ & 1 & 1 & 0 & 0\\ \hline
  3: & $\mathbb{o}_3$ & $P_3$ & 2 & 1 & 2 & 0\\ \hline
  4: & $\mathbb{o}_4$ & $P_4$ & 1 & 3 & 0 & 0\\ \hline
  5: & $\mathbb{o}_6$ & $P_6$ & 2 & 3 & 1 & 0\\ \hline
  \rowcolor{Maroon!50}
  6: & $\mathbb{o}_7$ & $P_7$ & 1 & 5 & 0 & 0\\ \hline
  7: & $\mathbb{o}_8$ & $P_8$ & 2 & 5 & 3 & 0\\ \hline
  \rowcolor{Maroon!50}
  8: & $\mathbb{o}_5$ & $P_5$ & 3 & 2 & 4 & 3\\ \hline
  \rowcolor{Maroon!50}
  9: & $\mathbb{o}_9$ & $P_9$ & 1 & 7 & 0 & 0
\end{tabular}
\label{tab:meptab}
\end{table}


Consider the multi-expressive enrichment table given in \autoref{tab:meptab}.
When selecting the 8th output row (with the first column entry $\mathbb{o}_5$) as reference, we reconstruct the normal enrichment table as layed out in \autoref{tab:exampleenrichmentgraph} by following the method defined above.

\subsubsection{Population Initialization}

After having given a definition of multi-expressive enrichment tables as well as a method to reduce them to normal enrichment tables, we will now provide an algorithm for the randomized generation of multi-expressive enrichment tables which will be used for our population initialization.
This algorithm will receive a set of prespecified dataset emitters $P^\bot$ and a corresponding set of configuration datasets $D^\bot$ as well as the number of rows it should generate.\\

We specify this algorithm using pseudo code in \autoref{lst:init}.

Note that we initially set the configuration datasets of all the enrichment operators to the empty dataset.
This is due to the fact that we employ a mechanism dubbed \emph{heuristic self-configuration} in order to derive the configuration datasets of enrichment operators on-demand while evaluating the multi-expressive enrichment table.

\begin{myfloat}[!p]
\begin{algorithm}[caption={[Random generation of multi-expressive enrichment tables]%
Random generation of multi-expressive enrichment tables. %
$P^\bot$ is the set of dataset emitters to be used. %
$D^\bot$ is the set of configuration datasets to be used for the dataset emitters. %
$o(m)$ is a function that returns a random enrichment operators with a maximum in-degree of {$m\in [1,2]$}. %
$k$ is the number of rows to be generated. %
$ \rnd(a,b) $ is a function returning a random number in {$[a,b]$}%  
}, label={lst:init}]
 input: $P^\bot$, $D^\bot$, $k$
 output: $\mathbb{T}$
 begin
   i $\gets$ 1 % row counter
   $\mathbb{T} \gets \emptyset$ % empty multi-expressive enrichment table 
   while i $\leq$ k 
     if ($k < |P_\bot|$) % insert dataset emitters
       $\mathbb{T}_i \gets (P^{\bot}_i, D^{\bot}_i, 0, 0, 0)$ 
     else
       $d \gets \rnd(1,\max(2, i-1))$
       $\mathbb{o}_{(n,m)} \gets o(d)$
       $d \gets n$
       if ($d = 1$)
         $\mathbb{T}_i \gets (\mathbb{o}, \emptyset, d, \rnd(1,i-1))$       
       else
         $\mathbb{T}_i \gets (\mathbb{o}, \emptyset, d, \rnd(1,i-1), \rnd(1,i-1))$      
       end
     end
     i $\gets$ i + 1      
   end
   return res
 end       
\end{algorithm}
\end{myfloat}

\subsubsection{Heuristic Self-Configuration of Enrichment Operators}
\label{ssec:selfconfig}

When evaluation a multi-expressive enrichment table, we denote the datasets resulting from evaluation of a given row $\mathbb{T}_i$ as $\mathbf{T}_i$.

The heuristic self-configuration of enrichment operators for a given row $\mathbb{T}_i$ is done by supplying the result of all its input rows $\left(\mathbb{T}_{i, 4}, \dots, \mathbb{T}_{i, \mathbb{T}_{i, 3}} \right)$ and $D_t$ (the target training dataset) to a method $\mathbb{s} \colon \mathcal{D}^n\times\mathcal{D}, n\in\{1,2\}$ that heuristically derives a configuration by searching for clues in the structture of the given \ac{RDF} datasets.

Each enrichment operator must supply such a method.
Deriving good heuristics for self-configuration is a very hard problem on its own and therefore will not be part of this thesis.\\

The enrichment operators we use here all specify a very simple heuristics for self-configuration and improvement of these methods should be part of future work in this field.

However, the complexity of the heuristics used here is not crucial for the evaluation of our approach in \autoref{ch:eval}, since we will specifically engineer the test cases in a way such that our simple heuristics have the chance of deriving the proper configuration, \emph{given that we just learn the proper structure of the graph}.\\

We therefore ommit a specification of heuristics to not burden the reader with a lot of formalism that has little to none utility in following the rest of this work.

Instead, now that we know about self-configuration, we will continue by describing the evaluation of a given genotype, \ie a multi-expressive enrichment table.

\subsubsection{Fitness Function}
\label{sssec:fitness}
%Let $\mathbf{T}_i$ be the result of evaluating a given genotype $\mathbb{T}$ up to the $i$th row.
Let $\mathbf{S}(D)$, $\mathbf{P}(D)$, $\mathbf{O}(D)$ denote the sets of subjects, predicates and objects\sidenote{Note that we exclude blank nodes from $\mathbf{S}(D)$ and $\mathbf{T}(D)$.} of a given dataset $D$, respectively.

We define a fitness function $\mathcal{f}$ as

\begin{equation}
  \begin{aligned}
    \mathcal{f} \colon \mathcal{D}^2 & \to \mathbb{R} \\
    (D_r, D_t) & \mapsto \frac{1}{4} \left( F_1\left( D_r, D_t \right) + F_1\left( \mathbf{S}(D_r), \mathbf{S}(D_t) \right) \right. \\
    & \left. + F_1\left( \mathbf{P}(D_r), \mathbf{P}(D_t) \right) + F_1\left( \mathbf{O}(D_r), \mathbf{O}(D_t) \right)\right)
  \end{aligned}
  \label{eq:fitness}
\end{equation}

where $F_1$ is the $F_1$-score as defined in \autoref{ssec:fscore}.

Informally, $\mathcal{f}$ measures similarity in terms of overlapping \ac{IRI} resources in subjects , overlapping \ac{IRI} resources in predicates and overlapping \ac{IRI} resources and literals in objects as well as overlapping triples.

\subsubsection{MEP-based Evaluation of Genotypes}
\label{sssec:mepgeno}
As our genotypes are represented as multi-expressive enrichment table $\mathbb{T}$, they correspond to multiple phenotypes, \ie normal enrichment tables.

To this end, we regard each row in $\mathbb{T}$ as a potential output row.
The evaluation of $\mathbb{T}$ is done row-wise and much similar to the evaluation of a normal enrichment table\sidenote{as specified in \autoref{ssec:enrichmenttable}} with the notable exception that we apply self-configuration to obtain the configuration dataset\sidenote{as specified in \autoref{ssec:selfconfig}}.\\

Furthermore, we will compute the fitness for the result of each row  as specified in \autoref{sssec:fitness}.

The effective fitness of a genotype is the maximum fitness of all its rows.
Moreover, we define the \emph{effective phenotype} of a given genotype as the normal enrichment table obtained by reconstruction\sidenote{as specified in \autoref{sssec:meet}} beginning at the row with the highest fitness value.

\subsubsection{General Notes}
\label{sssec:geneticoperators}

As we have seen previously, we use multi-expressive enrichment tables as genotypes.
These will have a fixed number of rows, denoted $r$.

Our population also consists of a fixed number of genotypes, denoted $p$.

We use a single-point crossover operator, which will swap rows of two genotypes at a random crossover point.\\

For mutation, we use an operator which randomly manipulates a given multi-expressive enrichment table in way such that their invariants\sidenote{That is, (1) rows must not have inputs from other rows with a higher row number than themselves and (2) rows must specify the right number of inputs for the in-degree of their corresponding dataset operator.} stay intact.\\

Finally, in each generation we use elitist selection\sidenote{The single best individual always survives.} in order to avoid decreasing the fitness of the best individual in the next generation.

Tournament selection with a tournament size of $3$ and a selection probability of $0.75$ is applied for determining the mating pool as well as for selecting the survivors.\\

Both the offspring and the survivors are subject to mutation.
We identify the offspring fraction $\frac{\mu}{\lambda}$, mutation probability $\sigma$ and mutation rate $\rho$ as the most important parameters for our approach.
They shall hence be considered hyperparameters and are subject to experimental investigation in \autoref{ssec:hpo}.\\

The algorithm will stop when
\begin{enumerate}
  \item a perfect solution ($\mathcal{f}=1$) is found,
  \item a maximum number $g$ of generations is exceeded, or
  \item the optional convergence detection mechanism\sidenote{See \autoref{ssec:convergence}.} commands termination.
\end{enumerate}

Now that we have given a complete overview of our baseline algorithm, we will present modifications of this baseline that we expect to improve the performance of the learning algorithm.

\subsection{Genotype Compaction}
\label{ssec:compaction}

The idea of enrichment table compaction is that we could speedup learning by restrucuring genotypes $\mathbb{T}$ in way such that we move the effective phenotype $\mathbb{T}_p$ of $\mathbb{T}$ to the front of the compacted genotype $\mathbb{T}'$.\\

This is done by first deriving $\mathbb{T}_p$ per the method described in \autoref{sssec:mepgeno}.
Let $|\mathbb{T}|$ denote the number of rows in $\mathbb{T}$.
Furthermore, let $\bot(\mathbb{T})$ denote the first one or two rows corresponding to dataset emitters in a given genotype $\mathbb{T}$.
We define $\top(\mathbb{T})=\mathbb{T}\backslash\bot(\mathbb{T})$.
The compacted genotype $\mathbb{T}'$ is then defined row-wise by 

\begin{equation}
  \begin{aligned}
    \mathbb{T}'_i & \coloneq \bot(\mathbb{T})_i  & \iff \quad & 1 \leq i \leq |\bot(\mathbb{T})| \\
    \mathbb{T}'_i & \coloneq \top(\mathbb{T}_p)_{i-|\bot(\mathbb{T})|}  & \iff \quad & |\bot(\mathbb{T})| < i \leq |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| \\
    \mathbb{T}'_i & \coloneq \texttt{rndrow()}  & \iff \quad & |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| < i \leq r
  \end{aligned}
  \label{eq:compacted}
\end{equation}

where \texttt{rndrow()} means that in this case we generate a new row randomly in way that is reflected by lines 10 through 17 of \autoref{lst:init}.\\

We apply genotype compaction randomly with a probability of $0.5$ to the whole population in the beginning of each generation.\\

In order to further minimize the size of the compacted genotype, we detect so called \emph{no-op} rows, remove them and repair the genotype.

As the reader should by now be familiar with our formalism, we ommit a formal specification of this process and instead limit ourselves to only defining how we \emph{detect} a \emph{no-op} row.

\paragraph{No-op detection.} Given a row $\mathbb{T}_i$, its output dataset $\mathbf{T}_i$ and its input datasets $I=\left(\mathbf{T}_{\mathbb{T}_{i, 4}}, \dots, \mathbf{T}_{\mathbb{T}_{i, \mathbb{T}_{i, 3}}}\right)$ we say that $\mathbb{T}_i$ is a \emph{no-op row}, iff $\mathbf{T}_i = D $ for some $ D\in I$.

\subsection{Semantic Genetic Operators}
\label{ssec:sgoapproach}

We define three semantic genetic operators, which we will present in the following.

\subsubsection{Subgraph Merging Crossover}

The idea behind our subgraph merging crossover is to combine two genotypes $\mathbb{T}$, $\mathbb{T}'$ in a way that increases the probability of learning a graph where both $\mathbb{T}$ and $\mathbb{T}'$ are part of its effective phenotype.\\

This is motivated by the observation that two sufficiently distinct good performing inherently confluent enrichment graphs could be merged into one by redirecting the vertices which have edges to their dataset acceptors to a new vertice with in-degree two.\\

Let $\mathbb{T}_p$, $\mathbb{T}_p'$ be the effective phenotypes of $\mathbb{T}$, $\mathbb{T}'$, respectively.
We apply this operator only if
\begin{equation*}
  |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}'_p)| \leq r
\end{equation*}

holds, otherwise we default to the single-point crossover.\\

In order to guarantee that the population size stays constant, the subgraph merging crossover needs to return two child genotypes.

To this end, we first compute both childs equally, but then we fill the $r-|\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}'_p)|$ remaining rows randomly for each child genotype.


If $r-|\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}'_p)|\geq 1$, we will also insert a row that merges the two subgraphs in $\mathbb{T}_p$ and $\mathbb{T}'_p$ with a probability of $0.25$.
To this end, we will randomly aquire an enrichment operator with an in-degree of two and set the input columns to the positions of the output rows of $\mathbb{T}_p$ and $\mathbb{T}'_p$ in the newly created child genotype.

Let $\mathbb{o}^{\text{merge}}_{(2,1)}$ be a randomly chosen enrichment operator with in-degree two.
Formally, a child genotype $\mathbb{T}^c$ is defined row-wise as

\begin{equation}
  \begin{aligned}
    \mathbb{T}^c_i  \coloneq & \bot(\mathbb{T})_i  & \iff \quad & 1 \leq i \leq |\bot(\mathbb{T})| \\
    \mathbb{T}^c_i  \coloneq & \top(\mathbb{T}_p)_{i-|\bot(\mathbb{T})|}  & \iff \quad & |\bot(\mathbb{T})| < i \leq |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| \\
    \mathbb{T}^c_i \coloneq & \top(\mathbb{T}_p')_{i-|\bot(\mathbb{T})|-|\top(\mathbb{T}_p)|}  & \iff \quad & |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| < i \\
    & & & \leq |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}_p')| \\
    \mathbb{T}^c_i \coloneq & \left(\mathbb{o}^{\text{merge}}_{(2,1)}, \emptyset, 2, |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)|, \right. & \iff \quad & i = |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}_p')| + 1 \\
    & \quad \left. \vphantom{\mathbb{o}^{\text{merge}}_{(2,1)}} |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}_p')| \right) & & \quad \leq r \land \rnd(1,4)=1 \\
    \mathbb{T}^c_i \coloneq & \texttt{rndrow()}  & \iff \quad & i = |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}_p')| + 1 \\
    & & & \quad \leq r \land \rnd(1,4) > 1\\
    \mathbb{T}^c_i \coloneq & \texttt{rndrow()}  & \iff \quad & |\bot(\mathbb{T})| + |\top(\mathbb{T}_p)| + |\top(\mathbb{T}_p')| + 1\\
    & & & \quad < i \leq r
  \end{aligned}
  \label{eq:semanticcrossover}
\end{equation}



\subsubsection{Precondition Broadcasting Mutation}

The idea of the precondition broadcasting mutation is to factor in a measure of \emph{how well a particular enrichment operator could replace another one} in a given row.

To this end, the enrichment operators need to provide an additional method $\mathbb{a}$, which takes the same kind of arguments that the self-configuration method does.
It then returns a real value between 0 and 1 which expresses the applicability of the enrichment operator, given the input and target datasets.\\

We ommit formal specifications for sake of brevity, as at this point it should be clear to the reader how these methods are defined.
The functionality of the precondition broadcasting mutation is as follows.

When a row $\mathbb{T}_i$ has been marked for mutation in a given genotype $\mathbb{T}$, we evaluate $\mathbb{T}$ up to $\mathbb{T}_i$ and obtain the evaluation results of its input dataset(s).
Subsequently we \emph{broadcast} the input dataset(s) together with the target training dataset to the applicability methods $\mathbb{a}$ of all available enrichment operators.
After the operators have returned their result, we initialize a roulette wheel selection where the portions of the virtual roulette wheel are proportional to the relative applicabilities of the operators.\\

Finally, we set $\mathbb{T}_{i,1}$ to the winner of the roulette wheel.

We chose the name \emph{postcondition broadcasting} for this method, as the input datasets to an enrichment operator can be regarded as its preconditions w.r.t. applicability.

\subsubsection{Postcondition Broadcasting Mutation}

The postcondition broadcasting mutation works similar to the precondition broadcasting mutation but in the reverse direction.

Therefore, we need to evaluate our genotype top-down instead of bottom-up.

To that end, enrichment operators need to supply a method $\mathbb{o}^{-1}$ that heuristically computes their inverse, again using the same arguments as the self-configuration method $\mathbb{s}$.

For sake of brevity, we ommit the definition of these methods here, but the interested reader can look them up in our source code.

\subsection{Convergence Detection Mechanism}

Our convergence detection mechanism is used to (1) detect convergence of our population and (2) prohibit convergence into a local optima by temporarily adjusting $\sigma$ and $\rho$.\\

In order to detect convergence, we keep track of the best fitness value and the standard deviation of fitness values in our generations.
We assert convergence if the best fitness value has not changed and the standard deviation of fitness values has been under a certain threshold $s_{\min}$ for the last ten generations.\\

When convergence is detected, we attempt to escape the potential local optima by temporarily setting $\sigma = \rho = 1$.
In the following generations, we lower them again by multiplication with a constant factor until they reach their initial values.

The algorithm finally terminates if after a fixed number of convergence detections and escape attempts no perfect solution is found.
